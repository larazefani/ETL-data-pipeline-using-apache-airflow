[2025-01-25T16:07:18.527+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-25T16:07:18.605+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-25T16:07:18.650+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-25T16:07:18.652+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-25T16:07:18.729+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-25T16:07:18.750+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=2953) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-25T16:07:18.759+0000] {standard_task_runner.py:72} INFO - Started process 2967 to run task
[2025-01-25T16:07:18.766+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '405', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmp3mzt01b4']
[2025-01-25T16:07:18.776+0000] {standard_task_runner.py:105} INFO - Job 405: Subtask fetch_ebook_data
[2025-01-25T16:07:19.888+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 50ab235b552a
[2025-01-25T16:07:20.242+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-25T16:07:20.246+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-25T16:07:20.247+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-25T16:07:20.249+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-25 16:07:18.607916+00:00
[2025-01-25T16:07:20.252+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-25T16:07:20.255+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-25T16:07:27.147+0000] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/app.py", line 42, in get_ebook_data
    df.drop_duplicates(subset="Title", inplace=True)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/frame.py", line 6566, in drop_duplicates
    result = self[-self.duplicated(subset, keep=keep)]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/frame.py", line 6698, in duplicated
    raise KeyError(Index(diff))
KeyError: Index(['Title'], dtype='object')
[2025-01-25T16:07:27.202+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-01-25T16:07:27.204+0000] {logging_mixin.py:190} INFO - Task start:2025-01-25 16:07:18.607916+00:00 end:2025-01-25 16:07:27.201003+00:00 duration:8.593087
[2025-01-25T16:07:27.206+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): fetch_ebook_data> dag:<DAG: fetch_and_store_ebooks> dagrun:<DagRun fetch_and_store_ebooks @ 2025-01-13 00:00:00+00:00: scheduled__2025-01-13T00:00:00+00:00, state:running, queued_at: 2025-01-25 16:07:02.736940+00:00. externally triggered: False>
[2025-01-25T16:07:27.208+0000] {logging_mixin.py:190} INFO - Failure caused by Index(['Title'], dtype='object')
[2025-01-25T16:07:27.211+0000] {taskinstance.py:1225} INFO - Marking task as UP_FOR_RETRY. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250125T160718, end_date=20250125T160727
[2025-01-25T16:07:27.261+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-25T16:07:27.263+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 405 for task fetch_ebook_data (Index(['Title'], dtype='object'); 2967)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 422, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/app.py", line 42, in get_ebook_data
    df.drop_duplicates(subset="Title", inplace=True)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/frame.py", line 6566, in drop_duplicates
    result = self[-self.duplicated(subset, keep=keep)]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/frame.py", line 6698, in duplicated
    raise KeyError(Index(diff))
KeyError: Index(['Title'], dtype='object')
[2025-01-25T16:07:27.336+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-01-25T16:07:27.767+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-01-25T16:07:27.773+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-25T17:02:45.182+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-25T17:02:45.615+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-25T17:02:45.752+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-25T17:02:45.773+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-25T17:02:46.111+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-25T17:02:46.182+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=3715) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-25T17:02:46.248+0000] {standard_task_runner.py:72} INFO - Started process 3745 to run task
[2025-01-25T17:02:46.264+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '450', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmp5x5hh518']
[2025-01-25T17:02:46.279+0000] {standard_task_runner.py:105} INFO - Job 450: Subtask fetch_ebook_data
[2025-01-25T17:02:47.678+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 50ab235b552a
[2025-01-25T17:02:48.924+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-25T17:02:48.931+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-25T17:02:48.955+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-25T17:02:48.976+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-25 17:02:45.617271+00:00
[2025-01-25T17:02:48.978+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-25T17:02:48.986+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-25T17:03:18.341+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-25T17:03:18.423+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-25T17:03:18.426+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250125T170245, end_date=20250125T170318
[2025-01-25T17:03:18.578+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-25T17:03:18.584+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-25T17:03:18.588+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-25 17:02:09.123039+00:00
[2025-01-25T17:03:18.591+0000] {logging_mixin.py:190} INFO - Task hostname:50ab235b552a operator:PythonOperator
[2025-01-25T17:03:18.678+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-25T17:03:18.942+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-25T17:03:18.970+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T06:34:15.070+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T06:34:15.355+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T06:34:15.590+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T06:34:15.592+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T06:34:17.597+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T06:34:17.647+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=391) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T06:34:17.669+0000] {standard_task_runner.py:72} INFO - Started process 433 to run task
[2025-01-26T06:34:17.677+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '544', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmpp5nlhh9w']
[2025-01-26T06:34:17.684+0000] {standard_task_runner.py:105} INFO - Job 544: Subtask fetch_ebook_data
[2025-01-26T06:34:18.093+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T06:34:18.867+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T06:34:18.891+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T06:34:18.895+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T06:34:18.905+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 06:34:15.418571+00:00
[2025-01-26T06:34:18.907+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T06:34:18.912+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T06:34:30.783+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T06:34:30.857+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T06:34:30.860+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T063415, end_date=20250126T063430
[2025-01-26T06:34:30.999+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T06:34:31.003+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T06:34:31.010+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 06:33:36.776070+00:00
[2025-01-26T06:34:31.019+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T06:34:31.159+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T06:34:31.504+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-26T06:34:31.530+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T07:22:10.814+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T07:22:10.960+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T07:22:11.018+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T07:22:11.023+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T07:22:12.088+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T07:22:12.233+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=1235) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T07:22:12.249+0000] {standard_task_runner.py:72} INFO - Started process 1274 to run task
[2025-01-26T07:22:12.348+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '630', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmpedgjszx6']
[2025-01-26T07:22:12.378+0000] {standard_task_runner.py:105} INFO - Job 630: Subtask fetch_ebook_data
[2025-01-26T07:22:12.891+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T07:22:13.818+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T07:22:13.837+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T07:22:13.845+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T07:22:13.848+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 07:22:10.963222+00:00
[2025-01-26T07:22:13.855+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T07:22:13.887+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T07:22:21.892+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T07:22:22.051+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T07:22:22.055+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T072210, end_date=20250126T072222
[2025-01-26T07:22:22.329+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T07:22:22.332+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T07:22:22.334+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 07:21:37.036909+00:00
[2025-01-26T07:22:22.337+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T07:22:22.534+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T07:22:22.606+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T07:47:36.023+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T07:47:36.197+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T07:47:36.320+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T07:47:36.329+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T07:47:36.721+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T07:47:36.765+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=1903) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T07:47:36.779+0000] {standard_task_runner.py:72} INFO - Started process 1948 to run task
[2025-01-26T07:47:36.791+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '725', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmpdfohhf09']
[2025-01-26T07:47:36.814+0000] {standard_task_runner.py:105} INFO - Job 725: Subtask fetch_ebook_data
[2025-01-26T07:47:37.428+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T07:47:38.337+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T07:47:38.355+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T07:47:38.359+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T07:47:38.375+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 07:47:36.203382+00:00
[2025-01-26T07:47:38.384+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T07:47:38.386+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T07:47:47.725+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T07:47:47.814+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T07:47:47.823+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T074736, end_date=20250126T074747
[2025-01-26T07:47:48.304+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T07:47:48.308+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T07:47:48.310+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 07:46:58.952545+00:00
[2025-01-26T07:47:48.322+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T07:47:48.517+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T07:47:48.694+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-26T07:47:48.727+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T08:51:32.576+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T08:51:32.788+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T08:51:32.938+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T08:51:32.943+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T08:51:34.420+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T08:51:34.473+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=3209) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T08:51:34.496+0000] {standard_task_runner.py:72} INFO - Started process 3244 to run task
[2025-01-26T08:51:34.484+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '878', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmp7m9vyndi']
[2025-01-26T08:51:34.505+0000] {standard_task_runner.py:105} INFO - Job 878: Subtask fetch_ebook_data
[2025-01-26T08:51:34.911+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T08:51:36.009+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T08:51:36.019+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T08:51:36.026+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T08:51:36.033+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 08:51:32.803810+00:00
[2025-01-26T08:51:36.047+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T08:51:36.054+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T08:51:46.997+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T08:51:47.400+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T08:51:47.456+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T085132, end_date=20250126T085147
[2025-01-26T08:51:49.059+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T08:51:49.074+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T08:51:49.090+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 08:51:00.154823+00:00
[2025-01-26T08:51:49.106+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T08:51:49.433+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T08:51:49.702+0000] {standard_task_runner.py:217} INFO - Process not found (most likely exited), stop collecting metrics
[2025-01-26T08:51:50.068+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-26T08:51:50.123+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T08:58:35.567+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T08:58:35.794+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T08:58:35.859+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T08:58:35.869+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T08:58:36.163+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T08:58:36.358+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '913', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmp7uxxayet']
[2025-01-26T08:58:36.343+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=3409) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T08:58:36.381+0000] {standard_task_runner.py:105} INFO - Job 913: Subtask fetch_ebook_data
[2025-01-26T08:58:36.388+0000] {standard_task_runner.py:72} INFO - Started process 3455 to run task
[2025-01-26T08:58:37.255+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T08:58:39.731+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T08:58:39.774+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T08:58:39.781+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T08:58:39.788+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 08:58:35.808217+00:00
[2025-01-26T08:58:39.790+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T08:58:39.791+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T08:58:49.146+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T08:58:49.275+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T08:58:49.280+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T085835, end_date=20250126T085849
[2025-01-26T08:58:49.982+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T08:58:49.991+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T08:58:49.999+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 08:57:53.462270+00:00
[2025-01-26T08:58:50.002+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T08:58:50.215+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T08:58:50.379+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-26T08:58:50.459+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T09:05:43.657+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T09:05:43.937+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T09:05:44.121+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T09:05:44.149+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T09:05:44.753+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T09:05:44.830+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=3616) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T09:05:44.855+0000] {standard_task_runner.py:72} INFO - Started process 3660 to run task
[2025-01-26T09:05:44.888+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '945', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmpc5qo6uqo']
[2025-01-26T09:05:44.935+0000] {standard_task_runner.py:105} INFO - Job 945: Subtask fetch_ebook_data
[2025-01-26T09:05:45.699+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T09:05:46.599+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T09:05:46.618+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T09:05:46.675+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T09:05:46.695+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 09:05:43.997011+00:00
[2025-01-26T09:05:46.699+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T09:05:46.727+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T09:05:55.393+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T09:05:55.437+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T09:05:55.455+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T090543, end_date=20250126T090555
[2025-01-26T09:05:55.521+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T09:05:55.537+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T09:05:55.539+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 09:05:01.303521+00:00
[2025-01-26T09:05:55.541+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T09:05:55.670+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T09:05:55.879+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-26T09:05:55.893+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T09:16:23.458+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T09:16:23.774+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T09:16:23.903+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T09:16:23.915+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T09:16:24.444+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T09:16:24.539+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '1014', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmpvlq7l048']
[2025-01-26T09:16:24.564+0000] {standard_task_runner.py:105} INFO - Job 1014: Subtask fetch_ebook_data
[2025-01-26T09:16:24.519+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=4020) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T09:16:24.725+0000] {standard_task_runner.py:72} INFO - Started process 4055 to run task
[2025-01-26T09:16:25.738+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T09:16:26.634+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T09:16:26.682+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T09:16:26.685+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T09:16:26.698+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 09:16:23.794594+00:00
[2025-01-26T09:16:26.705+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T09:16:26.710+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T09:16:36.311+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T09:16:36.419+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T09:16:36.438+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T091623, end_date=20250126T091636
[2025-01-26T09:16:36.571+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T09:16:36.578+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T09:16:36.582+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 09:15:51.434374+00:00
[2025-01-26T09:16:36.603+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T09:16:36.687+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T09:16:36.896+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-26T09:16:36.918+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-26T09:27:21.946+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-26T09:27:22.254+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T09:27:22.417+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [queued]>
[2025-01-26T09:27:22.449+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 2
[2025-01-26T09:27:23.078+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): fetch_ebook_data> on 2025-01-13 00:00:00+00:00
[2025-01-26T09:27:23.131+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=4337) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-01-26T09:27:23.201+0000] {standard_task_runner.py:72} INFO - Started process 4403 to run task
[2025-01-26T09:27:23.251+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'fetch_and_store_ebooks', 'fetch_ebook_data', 'scheduled__2025-01-13T00:00:00+00:00', '--job-id', '1067', '--raw', '--subdir', 'DAGS_FOLDER/app.py', '--cfg-path', '/tmp/tmpp19efm5y']
[2025-01-26T09:27:23.336+0000] {standard_task_runner.py:105} INFO - Job 1067: Subtask fetch_ebook_data
[2025-01-26T09:27:24.262+0000] {task_command.py:467} INFO - Running <TaskInstance: fetch_and_store_ebooks.fetch_ebook_data scheduled__2025-01-13T00:00:00+00:00 [running]> on host 34edd304782d
[2025-01-26T09:27:26.359+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='fetch_and_store_ebooks' AIRFLOW_CTX_TASK_ID='fetch_ebook_data' AIRFLOW_CTX_EXECUTION_DATE='2025-01-13T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-01-13T00:00:00+00:00'
[2025-01-26T09:27:26.440+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-01-26T09:27:26.461+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-01-26T09:27:26.500+0000] {logging_mixin.py:190} INFO - Current task name:fetch_ebook_data state:running start_date:2025-01-26 09:27:22.280634+00:00
[2025-01-26T09:27:26.512+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks and current dag run status:running
[2025-01-26T09:27:26.518+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-26T09:27:36.164+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-01-26T09:27:36.352+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-26T09:27:36.366+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=fetch_and_store_ebooks, task_id=fetch_ebook_data, run_id=scheduled__2025-01-13T00:00:00+00:00, execution_date=20250113T000000, start_date=20250126T092722, end_date=20250126T092736
[2025-01-26T09:27:37.868+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-01-26T09:27:37.892+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-01-26T09:27:37.899+0000] {logging_mixin.py:190} INFO - Dag name:fetch_and_store_ebooks queued_at:2025-01-26 09:26:24.926164+00:00
[2025-01-26T09:27:37.909+0000] {logging_mixin.py:190} INFO - Task hostname:34edd304782d operator:PythonOperator
[2025-01-26T09:27:38.244+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-26T09:27:38.264+0000] {standard_task_runner.py:217} INFO - Process not found (most likely exited), stop collecting metrics
[2025-01-26T09:27:38.866+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-26T09:27:39.121+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
